%%% File encoding is ISO-8859-1 (also known as Latin-1)
%%% You can use special characters just like ä,ü and ñ

\chapter{Appendix}

We have included sample solutions to each exercise. The skeleton code and provided APIs are omitted for concision, but can be found at \color{blue}\underline{\url{https://github.com/EvanFredHernandez/byose}}\color{black}.

\section{Warmup Solutions}

\begin{enumerate}
\item{The document vector is a vector of the tf-idf statistics for one document. There are many zeros because there is one feature for every meaningful word in the corpus, but only a small subset of all words appears in each document. Thus, there will be a zero tf-idf value for most words.}
\item{The normalized dot product measures how ``well aligned'' the two document vectors are in the feature space. This is a measure of how similar the two documents are. A larger normalized dot product means that the documents shared many terms with large tf-idf weights, so they are semantically similar. The results do make sense because both documents are about gold mines---they likely share many significant terms related to mining gold, giving them a large normalized dot product. On the other hand, the document about agriculture will have a small normalized dot product with the document on gold mining because they are unlikely to share many significant terms. We would hope this is the case, as they're documents on completely different subjects!}
\item{$XX^\intercal$ is a matrix where element $ij$ is the dot product of $d_i$ and $d_j$. Thus it is a matrix of non-normalized document similarities. $X^\intercal X$ would be a matrix where element $ij$ is the non-normalized dot product of the term $i$ and term $j$ vectors. In this case we have a matrix of non-normalized term similarities.}
\end{enumerate}

\section{Lab Solutions}
We provide code solutions for each part of the lab. The solutions can also be found and run at the GitHub repository. Some of the corpus initialization code was inspired by \cite{NLTK}. Please note that these are example solutions. Your code may look different and still work correctly. In particular, we have added optimizations for running certain computations in parallel and for caching precomputed data.
\\\\
To use our code solutions in your search engine, simply change the import statements at the top of \code{search\_engine.py} to be \code{partX\_sols.py} instead of \code{partX.py}.
\subsection{Part 1}
You should see that the resulting matrices have rank 2 and rank 300, respectively.
\lstinputlisting[language=Python, caption=Part 1 Code Solutions, firstline=5, lastline=22]{../part1_sols.py}

\subsection{Part 2}
Running \code{knn} on `training/1684' returns three documents that belong to the acquisitions category. Your k-nearest neighbors implementation should have around 89\% accuracy when tested against all of the Reuters categories put together.
\lstinputlisting[language=Python, caption=Part 2 Code Solutions, firstline=5, lastline=54]{../part2_sols.py}

\subsection{Part 3}
You will notice that the least squares and SVM classifiers behave comparably on both pairs of categories. However, the least squares classifier outperforms the SVM classifier in both cases by a small margin (about 10 misclassifications vs. about 4 misclassifications). Both classifiers perform worse on the second pair of categories because they are semantically similar, while the first pair is highly distinguishable and therefore easier to classify.
\lstinputlisting[language=Python, caption=Part 3 Code Solutions, firstline=5, lastline=98]{../part3_sols.py}

\subsection{Part 4}
You have a number of options for testing the search engine, but we suggest training only a fraction of the classifiers and then searching for documents within the trained categories. The search results will not always be perfect, particularly because the queries are sparse and therefore difficult to classify. Moreover, we have omitted any discussion of query enrichment or translation of queries into low-dimensional semantic space, so the query-to-document comparison accuracy will be off.
\lstinputlisting[language=Python, caption=Part 4 Code Solutions, firstline=5, lastline=14]{../part4_sols.py}